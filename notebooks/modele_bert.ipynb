{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27b06c2d-a906-4bc0-9671-d17f37ca444e",
   "metadata": {},
   "source": [
    "# 1. Importation des Bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4d6b57f-afaf-42b2-8a82-95ec5280fdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Master_Openclassroom\\python\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Conv1D, GlobalMaxPooling1D, Dropout\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import mlflow\n",
    "import mlflow.keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7f43e4-1b2a-44dd-9f34-cdcc0e25c028",
   "metadata": {},
   "source": [
    "# 2. Chargement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "866990a8-50a0-4856-9c67-ce0f2796da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données (en supposant que vous avez déjà les colonnes nettoyées)\n",
    "data = pd.read_csv('../data/database_p7_rework.csv')\n",
    "\n",
    "# Séparer les cibles (target) des textes\n",
    "y = data['target']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66521c0d-02bd-4dd7-9e21-b4ccf09838ab",
   "metadata": {},
   "source": [
    "# 3. Préparation des Données\n",
    "Tokenization avec BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55bb39b-c42e-4c74-9eed-fb9d641ff90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Master_Openclassroom\\python\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bert_model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "\n",
    "def encode_with_bert(texts, max_len=128):\n",
    "    return tokenizer(texts.tolist(), max_length=max_len, truncation=True, padding='max_length', return_tensors='tf')\n",
    "\n",
    "# Encodez les textes lemmatisés et stemmés avec BERT\n",
    "X_lemma_bert = encode_with_bert(data['text_lemmatized'])\n",
    "X_stem_bert = encode_with_bert(data['text_stemmed'])\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train_lemma_bert, X_test_lemma_bert, y_train, y_test = train_test_split(X_lemma_bert['input_ids'], y, test_size=0.2, random_state=42)\n",
    "X_train_stem_bert, X_test_stem_bert, _, _ = train_test_split(X_stem_bert['input_ids'], y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63160730-ec72-47bf-ac99-1c7f9288ba8f",
   "metadata": {},
   "source": [
    "# 4. Construction des Modèles\n",
    "Modèle CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec65c7b-8fb9-4040-8e91-6a66af668986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model_bert(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(128, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be40548-f157-4b95-8361-50ac0628cc2d",
   "metadata": {},
   "source": [
    "Modèle LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3bcc9b-15c6-46ee-8a57-750855492c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model_bert(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=input_shape, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6bbc71-0994-4041-b175-7a679a25f692",
   "metadata": {},
   "source": [
    "# 5. Entraînement des Modèles\n",
    "5.1 Entraînement CNN avec BERT + Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3055b1-0552-4a35-b6c7-2ad5764fd098",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()  # Terminer toute exécution en cours\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"preprocessing\", \"Lemmatization\")\n",
    "    mlflow.log_param(\"model_type\", \"CNN\")\n",
    "\n",
    "    cnn_model_lemma_bert = create_cnn_model_bert((128, 768))\n",
    "    cnn_model_lemma_bert.fit(X_train_lemma_bert, y_train, batch_size=32, epochs=5, validation_split=0.2, verbose=1)\n",
    "\n",
    "    mlflow.keras.log_model(cnn_model_lemma_bert, \"cnn_model_lemma_bert\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d829c3-9e4c-44ab-a474-0cdacbbcf2dc",
   "metadata": {},
   "source": [
    "5.2 Entraînement LSTM avec BERT + Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e54aa7-432c-42c2-9e0e-914f65879c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()  # Terminer toute exécution en cours\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"preprocessing\", \"Lemmatization\")\n",
    "    mlflow.log_param(\"model_type\", \"LSTM\")\n",
    "\n",
    "    lstm_model_lemma_bert = create_lstm_model_bert((128, 768))\n",
    "    lstm_model_lemma_bert.fit(X_train_lemma_bert, y_train, batch_size=32, epochs=5, validation_split=0.2, verbose=1)\n",
    "\n",
    "    mlflow.keras.log_model(lstm_model_lemma_bert, \"lstm_model_lemma_bert\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fef203-ebd1-459d-be89-58a3df24dbd5",
   "metadata": {},
   "source": [
    "5.3 Entraînement CNN avec BERT + Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79f9676-e270-473f-998d-bda9b18b6477",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()  # Terminer toute exécution en cours\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"preprocessing\", \"Stemming\")\n",
    "    mlflow.log_param(\"model_type\", \"CNN\")\n",
    "\n",
    "    cnn_model_stem_bert = create_cnn_model_bert((128, 768))\n",
    "    cnn_model_stem_bert.fit(X_train_stem_bert, y_train, batch_size=32, epochs=5, validation_split=0.2, verbose=1)\n",
    "\n",
    "    mlflow.keras.log_model(cnn_model_stem_bert, \"cnn_model_stem_bert\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d191cf8c-f586-48d0-8adc-6909ae550fbf",
   "metadata": {},
   "source": [
    "5.4 Entraînement LSTM avec BERT + Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d62d6b3-aa6c-455b-9af6-3ea19f260f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()  # Terminer toute exécution en cours\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"preprocessing\", \"Stemming\")\n",
    "    mlflow.log_param(\"model_type\", \"LSTM\")\n",
    "\n",
    "    lstm_model_stem_bert = create_lstm_model_bert((128, 768))\n",
    "    lstm_model_stem_bert.fit(X_train_stem_bert, y_train, batch_size=32, epochs=5, validation_split=0.2, verbose=1)\n",
    "\n",
    "    mlflow.keras.log_model(lstm_model_stem_bert, \"lstm_model_stem_bert\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c393cd53-270e-42bb-9a76-9f1faed79e0a",
   "metadata": {},
   "source": [
    "# 6. Évaluation des Modèles\n",
    "6.1 Évaluation du Modèle CNN avec BERT + Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eba5e0-8ed0-4254-baff-232a50d282e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions pour CNN + Lemmatization\n",
    "y_pred_cnn_lemma = (cnn_model_lemma_bert.predict(X_test_lemma_bert) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calcul de l'accuracy\n",
    "accuracy_cnn_lemma = accuracy_score(y_test, y_pred_cnn_lemma)\n",
    "print(\"Accuracy CNN + Lemmatization:\", accuracy_cnn_lemma)\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"Classification Report CNN + Lemmatization:\")\n",
    "print(classification_report(y_test, y_pred_cnn_lemma))\n",
    "\n",
    "# Matrice de confusion\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm_cnn_lemma = confusion_matrix(y_test, y_pred_cnn_lemma)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_cnn_lemma)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix CNN + Lemmatization\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93888128-1ccc-4f78-8ddb-b47166430574",
   "metadata": {},
   "source": [
    "6.2 Évaluation du Modèle LSTM avec BERT + Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b92fc8-9a31-402c-b7a0-599a4a2a3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions pour LSTM + Lemmatization\n",
    "y_pred_lstm_lemma = (lstm_model_lemma_bert.predict(X_test_lemma_bert) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calcul de l'accuracy\n",
    "accuracy_lstm_lemma = accuracy_score(y_test, y_pred_lstm_lemma)\n",
    "print(\"Accuracy LSTM + Lemmatization:\", accuracy_lstm_lemma)\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"Classification Report LSTM + Lemmatization:\")\n",
    "print(classification_report(y_test, y_pred_lstm_lemma))\n",
    "\n",
    "# Matrice de confusion\n",
    "cm_lstm_lemma = confusion_matrix(y_test, y_pred_lstm_lemma)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_lstm_lemma)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix LSTM + Lemmatization\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71760fa-17ad-4947-b561-df823a0eafc4",
   "metadata": {},
   "source": [
    "6.3 Évaluation du Modèle CNN avec BERT + Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f556f4-ceac-4ec9-b3f3-65e529e5aeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions pour CNN + Stemming\n",
    "y_pred_cnn_stem = (cnn_model_stem_bert.predict(X_test_stem_bert) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calcul de l'accuracy\n",
    "accuracy_cnn_stem = accuracy_score(y_test, y_pred_cnn_stem)\n",
    "print(\"Accuracy CNN + Stemming:\", accuracy_cnn_stem)\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"Classification Report CNN + Stemming:\")\n",
    "print(classification_report(y_test, y_pred_cnn_stem))\n",
    "\n",
    "# Matrice de confusion\n",
    "cm_cnn_stem = confusion_matrix(y_test, y_pred_cnn_stem)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_cnn_stem)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix CNN + Stemming\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b795ae5d-bd9e-4bb2-affc-0acde4378640",
   "metadata": {},
   "source": [
    "6.4 Évaluation du Modèle LSTM avec BERT + Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6ed2f4-ae96-4fb5-9676-31414f352cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions pour LSTM + Stemming\n",
    "y_pred_lstm_stem = (lstm_model_stem_bert.predict(X_test_stem_bert) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calcul de l'accuracy\n",
    "accuracy_lstm_stem = accuracy_score(y_test, y_pred_lstm_stem)\n",
    "print(\"Accuracy LSTM + Stemming:\", accuracy_lstm_stem)\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"Classification Report LSTM + Stemming:\")\n",
    "print(classification_report(y_test, y_pred_lstm_stem))\n",
    "\n",
    "# Matrice de confusion\n",
    "cm_lstm_stem = confusion_matrix(y_test, y_pred_lstm_stem)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_lstm_stem)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix LSTM + Stemming\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc051c0-29fe-44ab-a992-f5398085b7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
